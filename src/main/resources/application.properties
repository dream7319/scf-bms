server.port=8081

#datasource
spring.datasource.url=jdbc:mysql://192.168.151.13:3306/elastic?useUnicode=true&characterEncoding=utf8&autoReconnect=true&zeroDateTimeBehavior=convertToNull
spring.datasource.driver-class-name=com.mysql.jdbc.Driver
spring.datasource.username=root
spring.datasource.password=root
spring.datasource.poolName=hikariCP

#spring.mvc.static-path-pattern=/**
#spring.resources.static-locations=
#spring.jackson.date-format=yyyy-MM-dd

#mybatis
#mybatis-plus.mapper-locations=classpath:/mapper/*Mapper.xml
mybatis-plus.typeAliasesPackage=com.lierl.entity,com.lierl.api.spider.bean
#主键类型  0:"数据库ID自增", 1:"用户输入ID",2:"全局唯一ID (数字类型唯一ID)", 3:"全局唯一ID UUID";
mybatis-plus.globalConfig.id-type=0
#字段策略 0:"忽略判断",1:"非 NULL 判断"),2:"非空判断"
mybatis-plus.globalConfig.field-strategy=2
#驼峰下划线转换
mybatis-plus.globalConfig.db-column-underline=true
#刷新mapper 调试神器
mybatis-plus.globalConfig.refresh-mapper=true
#数据库大写下划线转换
#mybatis-plus.globalConfig.capital-mode=true
#序列接口实现类配置
#mybatis-plus.globalConfig.key-generator=com.lierl.entity
#逻辑删除配置
#mybatis-plus.globalConfig.logic-delete-value=0
#mybatis-plus.globalConfig.logic-not-delete-value=1
#自定义填充策略接口实现
#mybatis-plus.globalConfig.meta-object-handler=com.lierl
#自定义SQL注入器
#mybatis-plus.globalConfig.sql-injector=com.lierl
mybatis-plus.configuration.map-underscore-to-camel-case=true
mybatis-plus.configuration.cache-enabled=false

#添加那个目录的文件需要restart
spring.devtools.restart.additional-paths=src/main/java
#排除那个目录的文件不需要restart
spring.devtools.restart.exclude=src/main/webapp

#elasticsearch
#spring.data.elasticsearch.cluster-name=lierl
#spring.data.elasticsearch.cluster-nodes=127.0.0.1:9300
#spring.data.elasticsearch.repositories.enabled=true

logging.config=classpath:logback-lierl.xml


#kafka
spring.kafka.producer.bootstrap-servers=192.168.1.8:9092
#重试次数
spring.kafka.producer.retries=3
# 异步提交的时候(async)，并发提交的记录数
spring.kafka.producer.batch-size=200
# 设置缓冲区大小，默认10KB
spring.kafka.producer.buffer-memory=33554432
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer

spring.kafka.consumer.bootstrap-servers=192.168.1.8:9092
spring.kafka.consumer.enable-auto-commit=true
spring.kafka.consumer.group-id=0
spring.kafka.consumer.auto-offset-reset=latest
spring.kafka.consumer.max-poll-records=1000
spring.kafka.consumer.auto-commit-interval=100
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer

logging.level.com.lierl.api=info